# Functie voor installeren pakketten
pakketinstall <- function(pkg) {
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])] 
  if (length(new.pkg))  
    install.packages(new.pkg, dependencies = TRUE) 
  sapply(pkg, require, character.only = TRUE) 
}

# Installeren en libraries inladen 
packages <- c("...") 
pakketinstall(packages)

# Gebruikte pakketten in data prep, clean, analyse (tot aan RandomForest)

# "ROCR", "mice", "VIM", "ggplot2", "DMwR", "randomForest", "caret", 
# "dplyr", "pscl", "glmnet", "magrittr", "rpart", "rpart.plot", "ipred", 
# "C50", "ggcorrplot", "factoextra", "stringr", "purrr", "tidyr", "reshape2", 
# "RColorBrewer", "glmnet", "xgboost"

# Inlezen van data
getwd()
setwd( "...")

df <- read_csv("...")

# Na inladen dubblecheck en alle vars terug zetten naar factors.
df <- df %>%
  mutate_at(vars(2,3,5,6,16:27), as.factor)

str(df)
View(df)

# Laatste controle op missings
colSums(is.na(df))


# Random Forest-------------------------------------------------------------------------

# Altijd set.seed gebruiken: hiermee is je resultaat herhaalbaar!
set.seed(84)
rf <-randomForest(df$uitkomst~.,data=df, ntree=500) 
print(rf)
View(rf)

# Selecteren van de beste MTRY (hoeveel variabelen moet er bij elke node meegenomen worden)
set.seed(84)
str(df)
mtry_df <- df[,-uitkomst]
str(mtry_df)
mtry <- tuneRF(mtry_df,df$uitkomst, ntreeTry=500,
               stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)

best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
print(mtry)
print(best.m)

# De beste MTRY (het aantal variabelen wat bij elke node wordt meegenomen) is ...

#Trainen RandomForest met 10-fold CV

set.seed(84)
rf <- train(uitkomst ~ vars,
                  data = df.train,
                  method = 'rf',
                  trControl = trainControl(method = "repeatedcv",
                                           number = 10,
                                           savePredictions = "final",
                                           classProbs = T),
                  tuneLength = 1,
                  importance = TRUE)


print(rf)
preds <- predict(rf, df.test)
confusionMatrix(preds, df.test$uitkomst)

#AUC
y.test = df.test$uitkomst
auc <- prediction(as.numeric(preds), as.numeric(y.test))
round(performance(auc, measure = "auc")@y.values[[1]],3)


#accuracy         
#sens              
#spec             
#precision (PPV)     
#AUC        

Feauture engineering: plotten belangrijke vars

varimp.rf <- varImp(rf)
varimp.rf.rownames <- rf$importance
varimp.rf.rownames <- rownames(varimp.rf.rownames)

df.varimp.rf <- varimp.rf %>% 
  arrange(desc(varimp.rf$Overall))


x <- varimp.rf.rownames
x
y <- df.varimp.rf$Overall
y

plot.varimp.rf <- ggplot(data = varimp.rf, aes(reorder(x,y), y = y)) + 
  geom_bar(stat = "identity", aes(fill = Overall)) + 
  coord_flip() + 
  xlab("Variabelen") + 
  ylab("Importantie") +
  ggtitle("Waarde per variabele in RandomForest") +
  labs(fill = "Waarde") +
  theme_classic()

plot(plot.varimp.rf)

